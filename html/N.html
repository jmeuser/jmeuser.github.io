<html><head>
 <link rel="stylesheet" type="text/css" 
href="http://fonts.googleapis.com/css?family=Inconsolata">
 <link rel="stylesheet" href="../css/style.css" type="text/css" media="screen">
</head>
<body><pre>
N is a carefully crafted combination of math and computer science.

a b c  1 2 3  A B C
d . e  4 5 6  D , E
f g h  7 8 9  F G H
i j k  - 0 +  I J K  
l m n  % ! *  L M N
  o    &lt; = &gt;    O   
p q r  | ~ &amp;  P Q R
s : t  $ " ?  S ; T
u v w  #   @  U V W
x y z  ` ^ '  X Y Z
[ { (  / _ \  ) } ]

! rem   num
" rank
# take  shape
$ 
% quo   isqrt
&amp; meet
' quote
* times sgn
+ plus
, affix
- monus neg
. at|of
/ table over
: is
; link
&lt; min
= pd
&gt; max
?       type
@         
\ 
^ redo
_ drop  floor
`
| join
~ same  eval

clear
exact
simple
general
mnemonic
idiomatic
necessary
unavoidable
N-dimensional

Calculate and compute anything anywhere with N.

What is N?
N is new.
N is fast.
N is clear.
N is simple.
N is natural.
N is computable.
N is interactive.
N is highly parallel.
N is thought provoking.
N is a notational language.

N makes math easy.
N leverages our language instinct to transform vague intuition into practical 
exploration.
Decimals replaced Roman numerals: N replaces ancient notation for computing and 
calculating.
Use N on a black board, on a napkin, or on a computer.

No operator precedence: evaluate from right to left.

But what about "My Dear Aunt Sally"?
The classical notion of "order of operations" is an ancient habit as odd as 
using Roman numerals for arithmetic.
Its elimination gives simplicity, clarity, and generality to any algebraic 
expression.
It also eliminates the age old headaches of "what do I calculate first?"

Why would they teach order of operations in school if you didn't need it?
For the same reason the Roman's taught their children to use Roman numerals.

There has to be a catch! You must use a lot of parenthesis.
No catch, and no.

It must be like learning to read hieroglyphs!
It's not.

So you're just trying to make a "standard notation" for doing math with 
computers?
No.
We already have tons of standards and lots of notation.
N is a perspective on calculation and computation in math and science.
Its notation is a consequence of its perspective, not the other way around.

But, I don't get it.
Take a few deep breaths.
I'm making things simpler every day.
Soon you'll see the whys-and-hows at-a-glance.

Wait, isn't N just a flavor of APL, J, or k?
No.
k is a programming language.
N is a notational language.
The fact that N might be used to program computers is a consequence of its 
purpose, not its purpose.
k is for computation.
N is for calculation.
That computation is a type of calculation is surprisingly hard to prove (and in 
fact we often just assume tacitly there is a correspondence between computation 
and calculation).
N should and can be used anywhere: on paper, on a chalkboard, on a whiteboard 
etc.

But, can't you write k programs on a napkin if you wanted?
Yes.
You can write k programs by hand without worry because both k and N derive 
their notational conventions from Iverson's APL and J.

So then really, why should I be interested in N rather than k?
N is for calculations of all kinds: k is for computing.
Ultimately you can compute easily and efficiently with N, but its design is 
guided towards the fundamental limits of calculation with notation.

I still don't understand what the difference is between calculating and 
computing.
You seem to be making up the distinction without justification.

Try programming a computer to do algebra or calculus, you will discover that 
what is easy to calculate is not always so easy to compute.

Copyright John Meuser 2015
</pre></body></html>
