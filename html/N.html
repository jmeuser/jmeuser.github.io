<html><head>
 <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Inconsolata">
 <link rel="stylesheet" href="../css/style.css" type="text/css" media="screen">
</head>
<body><pre>
N is a carefully crafted combination of math and computer science.
Calculate and compute with N.

N is a notation.
N is computable.
N is natural.
N is fast.
N is clear.
N is simple.
N is interactive.
N is new.

N changes the way we think about math and computer science.

N leverages our language instinct to transform vague intuition into practical exploration.

Decimals replaced Roman numerals.
N replaces ancient notation for computing and calculating.

Design
clear and exact
unavoidable necessity
simplifying generality
idiomatic and mnemonic
eliminate obstacles to thought
N-dimensional

N is designed so that you'll love using it whether its on a black board, on a napkin, or on a computer.

One order of operations.
Evaluate everything from right to left.
That's it.

But what about "My Dear Aunt Sally"?
Gone, hopefully forever.
The classical notion of "order of operations" is ABSOLUTELY unnecessary.
In fact, its elimination produces greater clarity and generality in even the simplest algebraic expressions.
(It also eliminates the age old headaches of "what do I calculate first?")

There has to be a catch: you must use a lot of parenthesis.
No catch, and no.

But!
Just calm down, take a few deep breaths.
More likely than not you're feeling the terror from past mathematical trauma.
Elementary school can do quite a number on even the most eager minds.


Draft Material 

(don't look down here unless you're ready to see what it takes to turn an idea into an innovation)
(seriously, you'll get the wrong impression if you're not prepared)
(I warned you. Any impression you have past this point is no longer my responsibility, no matter how false it might be.)

What do you mean by exact?
If you want to compare things within a tolerance then you have to do so explicitly, otherwise N only deals with exact values, no approximations.

But what about all those beautiful real numbers?
We have a lot to talk about... real numbers have got to go.

Now you're really crazy! 
No reals? 
What about all those beautiful analytic results from functional analysis that are the bread and butter of signals processing!?
Ya... it's hard to accept, but we'll be fine without it, better even.

I don't believe you.
Don't take my word for it, Goodstein did most of the work in his Recursive Number Theory (1957) and Recursive Analysis (1961).

Oh, but that's all recursive stuff! No one wants to be worried about such a technical esoteric mathematical logical globidy gloopity: it's all just one big chore!

Life is one big chore.
Also, that's the exact response many people had to his original work: what a chore.
But, they never meant "what a chore" in a logical senses, they just found his evisceration of classical analysis revolting from a moral standpoint.
You might think of the response people had to early doctors learning of human anatomy by examining the dead.

Mathematics and morals? You have to be kidding.
Surprisingly, or perhaps not, mathematicians are people just like you or me.
They are prone to bouts of collective delusion just as much as any other group or club.
As computers have become more prevalent, it has been harder for certain delusions to persist: they must be confronted for us to continue moving forward.
Also, it's important to note that even Russell did not object to a philosophy congruent to that of Goodstein's works.
Rather he admitted that it was a path he did not have the heart to take after having confronted the foundations as he saw them.

Russell? Goodstein? Now you've gone and introduced philosophy into what you said was a practical problem.
This seems like nothing us mere mortals must worry ourselves with. 

Use space wisely.
Don't fear space.
Don't abuse space.
Balance space with proportion.
Space breaks N expressions into digestible chunks.
Space is the most powerful part of a sentence.

Separate nouns from verbs i.e. keep data away from the actions performed on it.
Similarities between subexpressions should be explicitly collected into a single subexpression e.g.

(3*x)+(3*y)+(3*z)

(3*x) + (3*y) + (3*z)

(3 * x) + (3 * y) + (3 * z)

(3*x)+ (3*y)+ (3*z)

(3* x)+ (3* y)+ (3* z) 

(3* x)+ (3* y)+ 3* z  This is an efficient way to write expressions with dyads

(3*x)+(3*y)+3*z  valid, but perhaps not wise

+/3* x,y,z This is how one would actually write and think of this expression

a:x,y,z    Or, as is more likely, this is the way it would be written
+/3*a



(x+1)*(x+2)*(x+3)

(x+1) * (x+2) * (x+3)

(x + 1) * (x + 2) * (x + 3)

(x+ 1)* (x+ 2)* (x+ 3)

(x+ 1)* (x+2)* x+ 3

(x+1)*(x+2)*x+3

*/x+ 1+!3

a:1+!3  remember, separate data from acts (nouns from verbs)
*/x+a



(x)+(x*(1+x))+(x*(1+x)*(2+x))+(x*(1+x)*(2+x)*(3+x))

x + (x*(1+x)) + (x*(1+x)*(2+x)) + (x*(1+x)*(2+x)*(3+x))

x + (x * (1+x)) + (x * (1+x) * (2+x)) + (x * (1+x) * (2+x) * (3+x))

x + (x * (1 + x)) + (x * (1 + x) * (2 + x)) + (x * (1 + x) * (2 + x) * (3 + x))

x+ (x* 1+ x)+ (x* (1+ x)* 2+ x)+ (x* (1+ x)* (2+ x)* 3+ x)

x+(x*1+x)+(x*(1+x)*2+x)+x*(1+x)*(2+x)*3+x

+/ (*/ x+!)" 1+!4

+/(*/x+!)" 1+!4

a:1+!4
+/(*/x+!)"a

a:1+!4
b:(*/x+!)" a
+/b

a:1+!4
f:(*/x+1)"
+/f a



1*2*3*4*5*6

1 * 2 * 3 * 4 * 5 * 6

1* 2* 3* 4* 5* 6*

*/ 1,2,3,4,5,6

*/ 1 2 3 4 5 6

*/1+! 6

*/ 1+!6

a:1+!6
*/a



x*(x+1)*(x+2)*(x+3)*(x+4)

x * (x+1) * (x+2) * (x+3) * (x+4)

x * (x + 1) * (x + 2) * (x + 3) * (x + 4)

x* (x+ 1)* (x+ 2)* (x+ 3)* x+ 4

x*(x+1)*(x+2)*(x+3)*x+4

*/ x,(x+1),(x+2),(x+3),x+4

*/ x+ 0,1,2,3,4

*/ x+ !5

*/x+ !5

*/x+! 5

x */+ !5

a:!5
*/x+a

a:!5
x */+ a



(1%t)*((2^t)%(1+t))*(((1+1%2)^t)%(1+t%2))*(((1+1%3)^t)%(1+t%3))

(1%t) * ((2^t)%(1+t)) * (((1+1%2)^t)%(1+t%2)) * (((1+1%3)^t)%(1+t%3))

(1 % t) * ((2 ^ t) % (1 + t)) * (((1 + 1 % 2) ^ t) % (1 + t % 2)) * (((1 + 1 % 3) ^ t) % (1 + t % 3))

(1% t)* ((2^ t)% 1+ t)* ((^t 1+ 1% 2)% 1+ t% 2)* (^t 1+ 1% 3)% 1+ t% 3

*/ 1%t , (^t 1+ 1%) % (1+t%) 1+!3

a:1+!3
b:1%t, (^t 1+ 1%)%(1+t%) a
*/b

a:1+!3
f:(^t 1+1%) % 1+t%
*/ (1%t),f a

a:1+!3
u:*/(1+1%a)^t
v:*/1+t%a
1%t * u%v

a:1+!3
u:*/^t 1+1%a
v:*/ 1+t%a
1%t * u%v

Note */ (1%t), (^t 1+ 1%)%(1+ t%) 1+!n is the n-th partial product of Euler's product expression for Gamma of t .

n choose k
(*/ n-) % (*/ 1+) !k
*/ (n-) % (1+) !k
*/ n- % 1+ !k
*/ n-%1+ !k
*/(n-%1+) !k
*/n-%1+ !k

A method of computing the k-th Laguerre polynomial at x
+/ (*/ x^ , 0n1^ , k-%1+.! , 1%*/.1+!) !1+ k

Another method (though the same, just not explicit i.e. breaking into parts)
C:{*/x-%1+ !y}   n C k means n choose k
f:*/1+!         f k means factorial of k
+/ (*/ x^ , 0n1^ , k.C , 1%f)!1+ k

Representation is not, in itself, enough to justify this notation.
Ease of manipulation and experimentation is what matters.
Eliminate variables, replace with pronoms.


N-dimensional statements are often simpler and clearer than their specific instances.
This is achieved using Iverson's adverb constructions.
Summation notation is replaced with +/ .
For example +/x+y*!z sums the first z terms of an arithmetic sequence.
It can be read from left to right as "plus over x plus y times enumerate z".
 
The unary verb ! is called enumerate.
It stores a rectangular array of consecutive numerals in row-major form.

 !0
()
 !10
0 1 2 3 4 5 6 7 8 9
 !3 3
0 1 2
3 4 5
6 7 8
 !3 3 3
 0  1  2
 3  4  5
 6  7  8

 9 10 11
12 13 14
15 16 17

18 19 20
21 22 23
24 25 26

Some may prefer to allocate !27 and store its shape somewhere else instead of using !3 3 3 .

"
Given a k-dimensional array with c-word elements A I"!k for (0&lt;|=I) &amp; I&lt;|=d (or &amp;/ &lt;|=2\ 0,I,d) we can store it in memory so that 
(A LOC I) = +/ (A LOC k#0), (*/ c, I, {1+ (1+x)_ d"!k})" 1+ !k
or
a:*/ c, {1+ (1+x)_ d !k}
(A LOC I) = +/ (A LOC k#0), a*I" 1+ !k
"From TAOCP V1E3 pg.299 (translated to N)

Notice, the math described here is also the code needed to implement this allocation method.

The meaning of the expression +/x+y*!z has great generality.
Each term of the sum is made by applying x+y* to an item of !z .
The expression x+y* or x+ y* stands for an arithmetical sequence starting at x with step size y.
An arithmetic sequence starting at 2 with step size 3 named s would be defined by writing

 s:2+3*
 s 0
2
 s 1
5
 2+3* 2
8
 2+ 3* 2
8
 s.2
8
 s 0 1 2 3
2 5 8 11
 s.0 1 2 3
2 5 8 11
 s.!4
2 5 8 11
 s !4
2 5 8 11
 s!4
2 5 8 11
 s"!4
2 5 8 11
 s"1 !4
2 5 8 11

Often, there is more than one way to say the same thing.

In general if s takes a numeral and returns a term of a sequence (i.e. if s is a verb) then +/s!n sums over the first n terms of s .
s need not give a simple numeral.
It may produce a matrix or higher dimensional array.
Suppose s:2*,2+,2- which is read "a is two times append two plus append two minus" then

 s 3
6 5 0n1

That is s 3 (or s.3) gives the vector 6 5 0n1 whose first component is 6, second component is 5, and third component is negative one.
Then

 a:2*,2+,2-
 (+/a"!3)=(a 0)+(a 1)+a 2
1
 (+/a"!3)=(2*,2+,2- 0)+(2*,2+,2- 1)+2*,2+,2- 2
1
 (2*,2+,2- 0)=(2*0),(2+0),2-0
1
 (2*0),(2+0),2-0
0 2 2
 (2*1),(2+1),2-1
2 3 1
 (2*2),(2+2),2-2
4 4 0
 (+/a"!3)=+/0 2 2;2 3 1;4 4 0
1
 +/0 2 2;
   2 3 1;
   4 4 0
6 9 3
 +/a"!3
6 9 3

That example shows how one can explore the meaning of the notation and play with math and computer science.
It is a simple example, and many find it unfamiliar, preferring the classical summation notation.
The reason is that in these simple examples, that is in the classical uses of summation notation, N seems clumsy.
The strength of N is in the simplicity of statements that are otherwise hard to express using classical summation notation.


N and Sums

Knuth, Graham, and Patashnik's Concrete Mathematics is probably the most passionate love poem to summations.
In it they embrace Iverson's square bracket notation, but ignore his / adverb.
Let's start by considering why they worship classical summation notation.
First, they call it "generalized Sigma-notation" on pg.22 and contrast it with delimitated summation.
Their first significant evidence is the sum of the first 100 odd squares.
First they present the "generalized Sigma-notation" for the sum of the squares of the first 100 odd integers:
  ___
  \      2
  /__   k  
0&lt;k&lt;100
  k odd

This is contrasted with the delimited form:

 ___49
 \           2
 /__   (2k+1)
   k=0

The savings being that the idea "sum the squares of all odd integers below 100" is better communicated in the former than the latter.
The purpose is to focus our attention on the information that we're not just squaring any numbers, we're square odd numbers.
And not just any odd numbers, those odd numbers that are less than 100.
The argument is that (1+2*k)^2 is a "bad" way to represent the square of an odd number when manipulating it in a proof using English as its metalanguage.
(one might write it as {^2 1+ 2*}k )

My contention is that N provides a much simpler interface to these concepts (both on a chalk board, in a book, and yes... on a computer).
First, the savings in generalized Sigma-notation comes from its encoding of the information "odds less than 100" by placing constraints on k.
Those constraints being "0&lt;k&lt;100" {0&lt; &amp; &lt;100}k (read "zero less and less one hundred k") and "k odd".
I would write this sum using N as follows.
First let olt mean "odds less than".
You might write it casually as:

olt:   odds less than

where everything following "   " is a comment.
You would read the expression "olt:   odds less than" as "olt is (or stands for) odds less than"
That being the principle information we must communicate.
I would then write the sum +/ ^2" olt 100 which reads "plus over power two each olt one hundred".
Or, for someone familiar with this notation (just as you would have to be to use "generalized sigma notation") it reads
"sum of the squares of odds less than one hundred"
Notice, there is no extraneous variable "k" there is only the information on what actions are to be performed.
Now, the real difference between the generalized sigma notation and the delimitated form is how we represent odds less than one hundred.
This is left un identified in N as we've used it.
To review, the whole N statement would be

olt:   odds less than
+/ ^2" olt 100

where it is obvious we have yet to specify how olt is "constructed".
In CM they've chosen to represent odd numbers as the result of applying 1+2* to a numeral.
One might define odd:1+2* so that odd n gives the n-th odd number.
Though, this doesn't make it easy to know whether odd.23 is less than 100 or not.
We could find out easily by listing out the first 100 odd numbers and seeing where they are less than 100:

 ?(odd!100)&lt;100
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49

This, being very close to k code, is read "where odd of enumerate 100 less 100".
An someone used to this notation would say "where the first 100 odds are less than 100".
We could select the maximum number (49) with

&amp;/?(odd!100)&lt;100

Which is read "meet over where odd of enumerate 100 less 100".
In this "pidgen" English you can instantly extract its meaning and means of computation.
So one could write the delimited form as

odd:1+2*
+/ ^2 odd &amp;/?100&gt;odd!100

Or, more as is done in Concrete Math,

+/^2 1+2*!49

Which is just as unexpressive as the standard delimitated sigma notation for such an expression.

The binary operation - is likely to be replaced by monus when used on natural numerals (chars).
When applied to an integer quantity (ints), like 0n2, it becomes minus.
Arguments are automatically promoted to the meet of their respective types.

As an example of using - with natural numerals and integer numerals:

 0-3
0
 5-6
0
 6-5
1
 0n0-5
0n5
 5n6-5
0n6
 

The notation for numerals is best thought of the building of compound nouns (komposita) as in Deutsch.

Some notational conventions
Bounds on the values expected for a pronom are denoted by mx and Mx

 {mx&lt; &amp; &lt;Mx}x

Notice that {mx&lt; &amp; &lt;Mx} or mx&lt; &amp; &lt;Mx is much different from {mx &lt;&amp;&lt; Mx} or mx {&lt;&amp;&lt;} Mx or mx &lt;&amp;&lt; Mx

For binding over a calculated value or compound noun parenthesis are needed

 &lt;(3 4 5) 4
0 0 1
 &lt;3 4 5 6
0 0 0
 &lt;3 (4 5 6)
0 0 0
 &lt;(3) 4 5 6
0 0 0
 &lt;(3+4) 4 5 6
1 1 1
 &lt;7 (4 5 6)
1 1 1
 &lt;7 4, 5, 6   / This gives some sense to this system of evaluation
1 1 1


 ? &lt;100 odd! 100
 ? &lt;100 odd.! 100

 ?. &lt;100. odd. !. 100

 (?@&lt;100@odd@!)


a b c  # ! 0  A B C
d ` e  1 2 3  D ' E
f g h  4 5 6  F G H
i j k  7 8 9  I J K  
l m n  + - *  L M N
  o    :   ;    O   
p q r  &lt; = &gt;  P Q R
s . t  | ~ &amp;  S , T
u v w  $ _ @  U V W
x y z  % ^ ?  X Y Z
{ ( [  / " \  ] ) }

  ! " # $ % &amp; ' ( ) * + , - . /
0 1 2 3 4 5 6 7 8 9 : ; &lt; = &gt; ?
@ A B C D E F G H I J K L M N O
P Q R S T U V W X Y Z [ \ ] ^ _
` a b c d e f g h i j k l m n o
p q r s t u v w x y z { | } ~

! remainder    enumerate
" rank
# take         shape
$
% quotient
&amp; meet
'
* times        signum(type)
+ plus
, append
- m[oi]nus     negate
. of
/ over         table (generalized Kronecker product)
: is
; (link?)
&lt; less
= equal
&gt; more
?              where
@
[
\ infix        prefix 
]
^ repeat
_ drop         floor
`
{ 
| join
}
~

Classical Compositions
(f g h y) and (f @ g @ h y) give (f (g (h y)))

f
|
g
|
h
|
y

(x f g h y) and (x f @ g @ h y) give (x f (g (h y)))

  f
 / \
x   g
    |
    h
    |
    y

(g h y) and (g @ h y) give (g (h y))

g
|
h
|
y

(x g h y) and (x g @ h y) give (x g (h y))

  g
 / \
x   h
    |
    y

(f0 f1 ... fn g h y) and (f0 @ f1 @ .. @ fn @ g @ h y) give (f0 (f1 ..(g (h y))..))

f0
|
f1
|
:
|
fn
|
g
|
h
|
y

(x f0 f1 .. fn g h y) and (x f0 @ .. @ fn @ g @ h y) give (x f0 (f1 ..(g (h y))..)

  f0
 / \
x   f1
    |
    :
    |
    fn
    |
    g
    |
    h
    |
    y

Forks
(f g h) is a fork of f`g`h
((f g h) y) gives ((f y) g (h y))

  g
 / \
f   h
|   |
y   y

(x (f g h) y) gives ((x f y) g (x h y))

    g
   / \
  f   h
 /|   |\
x y   x y

Claws
(g h) is a claw of g`h
((g h) y) gives (g (h y))

 g
 |
 h
 |
 y

(x (g h) y) gives (g (x h y))

  g
  |
  h
 / \
x   y

(f ]) and (f [) makes f monadic (on either the left or right argument)

Trains
(f0 f1 .. fn g h) is a train of f0`f1`..`fn`g`h
if n is even then the train (f0 f1 .. fn g h) is a fork of forks
if n is even ((f0 f1 .. fn g h) y) gives ((f0 y) f1 (..((fn y) g (h y))..))

f1
| \
f0 f3
|  | \
y  f2 f5
   |  | \
   y  f4 :
      |   \
      y    g
          / \
         fn  h
         |   |
         y   y

if n is even (x (f0 f1 .. fn g h) y) gives ((x f0 y) f1 (..((x fn y) g (x h y))..))

  f1
  | \
  f0 f3
 /|  | \
x y  f2 f5
    /|  | \
   x y  f4 :
       /|   \
      x y    g
            / \
           fn  h
          /|   |\
         x y   x y

if n is odd then the train (f0 f1 .. fn g h) is a claw of forks
if n is odd ((f0 f1 .. fn g h) y) gives (f0 ((f1 y) f2 (..((fn y) g (h y))..)))

f0
|
f2
| \
f1 f4
|  | \
y  f3 :
   |   \
   y    g
       / \
      fn  h
      |   |
      y   y

if n is odd "x(f0 f1 .. fn g h)y"gives "(f0 (x f1 (..((x fn y)g(x h y))..)))"

  f0
  |
  f2
  | \
  f1 f4
 /|  | \
x y  f3 :
    /|   \
   x y    g
         / \
        fn  h
       /|   |\
      x y   x y


a b c  # ! 0  A B C
d ` e  1 2 3  D ' E
f g h  4 5 6  F G H
i j k  7 8 9  I J K  
l m n  + - *  L M N
  o    :   ;    O   
p q r  &lt; = &gt;  P Q R
s . t  | ~ &amp;  S , T
u v w  $ _ @  U V W
x y z  % ^ ?  X Y Z
{ ( [  / " \  ] ) }

The notation used here is highly idiomatic and mnemonic.
It is inspired by Iverson's J and APL, and Whitney's k.
Its use as a tool for thinking about math is inspired by Goodstein.
It's use for programing is inspired by Iverson.

There is one order of operations: expressions are evaluated from right to left.
Expressions are read aloud from left to right.

!0 gives the empty or null list ()

Rather than write

   !0     input     antecedent
--------- calculate action
   ()     output    consequent

we write

   !0
()

so that the antecedent event is preceded by some space and the output is not.
This sequence of events is read "enumerate zero gives the null list".
Although a native English speaker might say "Enumerating zero gives the empty list".

This sequence of events shows the result of enumerate of a few natural numerals.

   !0
()
   !1
0
   !2
0 1
   !10
0 1 2 3 4 5 6 7 8 9
   !15
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14

We can describe ! in terms of itself using join.

   !10
0 1 2 3 4 5 6 7 8 9
   (!9),9
0 1 2 3 4 5 6 7 8 9

To show how to calculate (!9),9 we separate it into a sequence of intermediate events.

       (!9),9          enumerate nine join nine
---------------------  evaluate enumerate nine
(0 1 2 3 4 5 6 7 8),9  join the list 0 1 2 3 4 5 6 7 8 to nine
---------------------  calculate
 0 1 2 3 4 5 6 7 8 9   the vector 0 1 2 3 4 5 6 7 8 9

Notice that there are many different ways of saying the same thing.
Only context can tell us why we might say things one way rather than another.
For example we could have written the previous sequence of events as follows:

      (!9),9
-------------------
0 1 2 3 4 5 6 7 8,9
-------------------
0 1 2 3 4 5 6 7 8 9

The difference is subtle, and it often is, but some contexts benefit from the one over the other.
Here is a, seemingly complex, way of calculating the result of evaluating '!5'

                    !5
----------------------
                (!4),4
----------------------
            ((!3),3),4
----------------------
        (((!2),2),3),4
----------------------
    ((((!1),1),2),3),4
----------------------
(((((!0),0),1),2),3),4
----------------------
 ((((((),0),1),2),3),4
----------------------
     ((((0),1),2),3),4
----------------------
       (((0,1),2),3),4
----------------------
       (((0 1),2),3),4
----------------------
         ((0 1,2),3),4
----------------------
         ((0 1 2),3),4
----------------------
           (0 1 2,3),4
----------------------
           (0 1 2 3),4
----------------------
             0 1 2 3,4
----------------------
             0 1 2 3 4

Someone familiar with enumerate of a numeral would probably just write

   !5
0 1 2 3 4

Some people might say "count out five" for !5 or maybe "aufzuzählen fünf".

"Why use ! for enumerate when we already use it to talk about factorials?" you ask.
First, you can write */!n for the factorial of n-1.
Second, you can do much more with ! this way than as a factorial (MUCH more).
Second and a half, factorial isn't nearly as simple or general as ! as enumerate.
Third, calculating with factorial is difficult.
It occurs frequently, and grows fast.
It is only one of a large family of similar functions.
Pick your favorite binary operation T then T/!n gives you its factorial like extension.
In general T/a is read "T over a".
If a:2 4 0 1 12 then (T/a)=2 T 4 T 0 T 1 T 12.
If the idea of right to left evaluation is new you might prefer to think of it this way
(T/a) = (2 T(4 T(0 T(1 T 12))))
So if T:+ then (T/a)=+/a and
(+/a) = 2+4+0+1+12
So you might notice a familiar factorial like function with T:+
(+/!5) = 0 + 1 + 2 + 3 + 4
In general, if n is a natural numeral then
(+/!n)=(n-1)*n%2
We can prove this by induction on n.
First, we assume that n is a natural numeral and not something like a function or vector.
Notice that (+/!0)=+/() and 0=(0-1)*0%2 so that +/() should give 0 (and it does).
See that () looks like 0.
It often plays the same role as 0 when calculating with vectors.
So we know (+/!0)=(0-1)*0%2.
Suppose (+/!n)=(n-1)*n%2 for some numeral n.
By basic arithmetic and algebra the following list of expressions give the same numeral:
+/!1+n
+/(!n),n
(+/!n)+n
n+ +/ !n
n+ (n-1)* n%2
((2*n)+(n-1)*n)%2
(2+n-1)*n%2
(1+n)*n%2
(1+n)*(1+n-1)%2
This completes the induction.

Another familiar family of functions are the repeated T functions.
Again, pick your favorite dyad T then T/# gives its repeated extension.
We'll let T:+ in the following sequence of equivalent expressions.
3+/#4
+/3#4
+/4 4 4
4 + 4 + 4
12
Notice that 3+/#4 is the same as 3*4.
This is not surprising since multiplication is often synonymous with repeated addition.
We can continue this process to power or exponentiation:
3*/#4
*/3#4
*/4 4 4
4 * 4 * 4
64
The name for repeated exponentiation was created by Goodstein: tetration.
In the following expressions let T:*/#
3T/#4
T/3#4
T/4 4 4
4 */# 4 */# 4
13407807929942597099574024998205846127479365820592393377723561443721764030073546976801874298166903427690031858186486050853753882811946569946433649006084096
Which is an example of a number that would have given C programmers a small headache "back in the day".
The hierarchy of repeated extensions of + (or of succession) is very interesting.
As you climb up it's easy to make functions that grow faster than what we tend to imagine as being "fast".

The number of items in a list is returned by count:
n=#!n
4=#4 4 4 4
(#1 2 3 4)=#0 1 2 3

Why use such a strange notation to say what we already say with regular math notation?
These notational conventions reveal similarities between operations that are often defined using wildly different notation or notions.
As has already been shown, any operation that is born from the repetition is give as T/#.
There is more to this notation if we consider binary operations as parametrized unary operations (this is in the spirit of currying, but has been surprisingly familiar to accountants around the world for a long while).
Suppose you ask an accounting to add the following list of numerals:
12 23 424 244 3535 54
If their calculator wasn’t already cleared they would clear it and start by typing 54 then + which would add 54 to 0 since clearing a calculator starts its value at 0.
Then they would type 3535+ followed by 244+, 23+, and 12+ finally reaching the sum 4292.
We summarize these steps by writing:
12+ 23+ 424+ 244+ 3535+ 54+ 0
Thus it is revealed that 54+ is an operation called "add 54 to" or "54 plus".
It is one of a wide family of operations e.g. 12+ "add 12 to" or 23+ "add 23 to"
Now, the expression
12+ 23+ 424+ 244+ 3535+ 54+ 0
becomes the successive composition of parametrized unary operators applied to 0.
Grouping with parenthesis will separate out the actions from the noun:
(12+ 23+ 424+ 244+ 353+ 54+) 0
It is this simple example which suggests a strong and far reaching generalization: use space, or a lack there of, to group and build and denote different compositions of actions.
One might write
(-12 12+ 8- +23) 0
for what is traditionally written (and should/still can be written conveniently as)
(12+8-23+0)-12
But, in the second case, we have removed any sense of successive actions.
There is also the issue of "ambiguity" as to whether -12 is an operation "minus twelve" or denotes a quantity "negative twelve".
The resolution of this ambiguity is found in the origin of negative quantities as a tool for recording debits and credits, or gains and losses.

Historically, the natural numerals 0 1 2 3 4 5 and so on were the only quantities worth considering as "actual", "real", or "existent" quantities.
(though it took some time for 0 to be thought of as denoting a quantity which could be "measured" as we tend to use the word today)
The idea which led to today's conception of "negative numbers" is found in recording gains and losses using natural numerals.
A gain of 3 and a loss of 4 would be interpreted as a net loss of 1.
The notion of "net loss" or "net gain" is born from the canonicalization of a table of gains and losses.
These canonical "net gains" or "net losses" are what developed into the modern mathematician's positive and negative numbers i.e. integers.

We consider a single trading event which is recorded as a quantity of gains and a quantity of losses.
A gain of 3 and loss of 4 is denoted 3n4
A gain of 5 and loss of 25 is denoted 5n25
A gain of 0 and loss of 15 is denoted 0n15
A gain of 3 and loss of 0 is denoted 3n0 or, simply, 3.
Thus the unary operation "negate", which is denoted either 0- or -: works as follows
   -:3
0n3
   0- 3
0n3
   0 - 3
0n3
   - 3
0n3
   -3
-3
In the last case -3 is a unary operation "minus three" where as - 3 is "negate 3".
Notice that "negate three" is a two word command and the verb "negate" is separated from the noun "three" by a space just as in - 3.
The convention that -:3 represents "negate 3" is from :'s use as an adverb when put right next to a verb.
There is much more that can be said about that later.

For those who object out right to the use of 0n3 to denote what is commonly referred to as "negative three" I will suggest a bit of patience, as many numbers are the result of this same general pattern, and we should consider the origins of such concepts as not only historically interesting but interesting from a pedagogical or behavioral perspective.

Consider fractions.
Given a pie we are asked how to share it among four children.
Certainly each child wishes to have part of the pie, and no one child would wish their part to be smaller than any other's part.
Since there are four children, the whole pie must be broken into four parts.
Since no child wishes to have less than another, the parts must be equal.
Finally, we give each child one of the four parts of the pie.
From this simple, and commonly occurring event, we get numbers for sharing i.e. fractions.
The one part each child receives from the whole pie is said to be "one forth" of the pie.

Suppose a party is planned and eight children are to be there.
The pie is cut into eight parts, each being equal to the other in order to eliminate any sense of "unfairness" among the children.
Due to inclement weather, only four children end up at the party.
These children, still wishing to have their fair share of pie, are given two out of the eight parts of the whole pie.
Thus, each child is said to have received "two eighths" of the pie.

The realization that "one forth" of a pie is the same amount of pie as "two eights" of a pie comes from comparing the relative sizes of the resulting collection of pie pieces.
Here "one of four parts" is denoted by 1f4 (though, ultimately the use of 'f' is inconsequential as long as it is easily distinguished from the other numeral notation introduced here).

The question "is one of four parts the same as two of eight parts" is asking whether two methods of dividing a whole into parts and then selecting some of those parts give the same quantity.
Here, the single trading event is an act breaking a whole into an equal number of parts and selecting a number of those parts.
We record such an event by making a table of the number of equal parts the whole is broken into and the number of parts selected.
So 1f2 records an event where some whole is broken into two equal parts and one of those parts is retained.
Similarly 2f4 records an event where some whole was split into four equal parts and two of those parts were kept.
The fact that a record of 1f2 is similar to a record of 2f4 (given the same whole) is what leads to the modern mathematician's notion of rational numbers.
The use of canonical records (e.g. 1f2 for 2f4 or 16f32) is what most people think of as "rational numbers" rather than the companion concept of "fractions".

What has been revealed thus far is a bit misleading.
Certainly, there is reason to have notation for "negative numbers" or "rational numbers" but is it necessary to separate -:3 from 0n3?
One could just as easily write 0-3 for 0n3 since 0n3 is the result of evaluating 0-3.
In general k-(3+k) gives 0n3 for any numeral k.
Ultimately, it is a matter of choice which notation is used in which situation, but it is important to know that 0n3 is a noun, a record of an event, where as 0-3 is a command which says "subtract 3 from 0" and in some contexts the one is much preferable to the other.

Similar statements apply to fractions when division is introduced.
Here 2%4 gives 1f2 which is the same as the result of 1%2 or 16%32.

What about negative fractions?
   -:2%4
0n1f2
Some people might find such numbers mixed with letters frightening, and that's okay.
One thing that this reveals though is a very important thing about fractional numerals: they are really triples of natural numerals.
The quantity denoted by 3n4f2 is equivalent to 0n1f2 and not 3n2f1.

One can also use (-2%3) to stand for 0n2f3, but the parenthesis matter in this case since - is only interpreted as "negate" because there is a parenthesis to its left and evaluation always precedes from right to left.

-2%3
-----
-2f3
-----
0n2f3

Notice that no parenthesis are used here.
That is because there is nothing else that the expression -2%3 is part of so it is easily known that - means "negate" in this context.

In the notation used here the result of evaluating (-2%3) is different from the result of evaluating (-2 %3).
As has been said (-2%3) gives 0n2f3 but

 -2 1%3
-------
 -2 1f3
-------
 1f3-2
-------
1f3-6f3
-------
 0n5f3

There is certainly good reason for perhaps interpreting -2 %3 in a different way.
Some might wish for -2 %3 to give a vector 0n2 1f3.
For them there are at least two choices: (-2) (%3) or -:2 %:3.

Having gotten this far you might wonder if it's really all worth it.
Math seems to be doing fine without worrying about this unfamiliar notation that seems to say only what has already been said about math.
The "superficial" point of difference of this notation is that mathematical expressions built with this notation are immediately computable so that experimentation is as simple as with classical calculators only much more is expressible with only a minimal amount of new notation.

The true value, purpose, or relevance of this notation is hard to communicate because its fundamental point of difference either goes unseen by most mathematicians/computer scientists or is outright denied as being a "relevant" point of difference.
First, it promotes a finite perspective on mathematics.
Some use the words "constructive" or "intuitionistic", but neither is fully meant here.
A consequence of following this notational discipline is that the mathematics done is constructive, as far as "being constructive" has a well defined meaning in the first place.
Furthermore, results are "intuitionistic" in that they will not be beyond what can be expressed in an mathematics built on an intuitionistic logic.
But in both cases, neither constructivity nor intuitionistic constraints are what is aimed at.

As a slogan, one might say, as Leopold Kronecker did, that "God made the integers; all else is the work of man", but I would rather say that humans created numerals and all else is the work of humans.
Perhaps another slogan is Feynman's (or Dirac's or Mermin's) "Shut up and calculate".
Though their use of the phrase would permit mathematical tools which are denied here (specifically tools from non-recursive analysis).

Some Collected Drafts
a&lt;|=b       a less or equal b
*/1+!n      times over one plus enum n (factorial of n)
+/%#a       plus over quotient num of a (average of a)
+/a*x^!#a   polynomial in x with coefficients a (p:{+/x*y^!#x} so that (1 3 5 7)p is a polynomial operator)
(+/!1+n)=n*(1+n)%2
(!n m)=(!n);n+!m
(x^y)=*/x#y
(*/x#y)=x*/#y claws can be very helpful
(+/a*x^!#a)=+/a**/x#"!#a suggest dyadic ^ is suspect like ! as factorial.
(+/a*x^!#a)=*/b-x for some b with (#b)=#a (fundamental theorem of algebra) (add awesome generalizations that simplify)

e:*/#         /power i.e. x e y is "x to the y"
r:{x*/+(!y)}  /raising factorial power i.e. 'x r y' is "x to the y rising"
f:{*/!1+x}    /factorial of
a:            /finite sequence of numerals
b:            /finite sequence of numerals
F:{+/(a r\: * y e % b r\: * f)!x}
k F           /k-th partial sum of a,b-hypergeometric operator

+/(a (*/+)\: * z (*/#) % b (*/+)\: * (*/!:1+))!k  /k-th partial sum of a,b-hypergeometric function at z

The following draft material is written using an older form of N notation.
A language grows, it doesn't just blip into existence overnight.

Notes on Basic Math by Serge Lang

Contents

Part I Algebra

Chapter 1 Numbers
The integers
Rules for addition
Rules for multiplication
Even and odd integers; divisibility
Rational numbers
Multiplicative inverses

Chapter 2 Linear Equations
Equations in two unknowns
Equations in three unknowns

Chapter 3 Real Numbers
Addition and multiplication
Real numbers: positivity
Powers and roots
Inequalities

Chapter 4 Quadratic Equations

Interlude On Logic and Mathematical Expressions
On reading books
Logic
Sets and elements
Notation

Part II Intuitive Geometry

Chapter 5 Distance and Angles
Distance
Angles
The Pythagorean theorem

Chapter 6 Isometries
Some standard mappings of the plane
Isometries
Composition of Isometries
Congruences

Chapter 7 Area and Application
Area of a disc of radius r
Circumference of a circle of radius r

Part III Coordinate Geometry

Chapter 8 Coordinates and Geometry
Coordinate systems
Distance between points
Equations of a circle
Rational points on a circle

Chapter 9 Operations on Points
Dilations and reflections
Addition, subtraction, and the parallelogram law

Chapter 10 Segments, Rays, and Lines
Segments
Rays
Lines
Ordinary equation for a line

Chapter 11 Trigonometry
Radian measure
Sine and cosine
The graphs
The tangent
Addition Formulas
Rotations

Chapter 12 Some Analytic Geometry
The straight line again
The parabola
The ellipse
The hyperbola
Rotation of hyperbolas

Part IV Miscellaneous

Chapter 13 Functions
Definition of a function
Polynomial functions
Graphs of functions
Exponential function
Logarithms

Chapter 14 Mappings
Definition
Formalism of mappings
Permutations

Chapter 15 Complex Numbers
The complex plane
Polar form

Chapter 16 Induction and Summations
Induction
Summation
Geometric Series

Chapter 17 Determinants
Matrices
Determinants of order 2
Properties of 2 by 2 determinants
Determinants of order 3
Properties of 3 by 3 determinants
Cramer's Rule

Numbers

The Integers
(Z. *. 0 &lt;) n means n is a positive integer e.g. 1 2 3 4 5 6 7 8 9 10 11
0 = n means n is zero
N. n means n is a natural number i.e. zero or positive integer
natural number line with origin labeled 0
(Z. *. 0 &gt;) n means n is a negative integer e.g. _1 _2 _3 _4 _5 _6 ..
Z. n means n is an integer (zero, positive integer, negative integer)
integer number line as iterated measurement from 0
addition as iterated motion on the number line
(Z. n) implies (n = n + 0) and n = 0 + n
n - ~ as (- n) +   subtraction as adding a negative
(Z. n) implies (0 = n + - n) and 0 = (- n) + n
n and - n are on opposite sides of 0 on the standard number line
read - n as "minus n" or "the additive inverse of n"

Rules For Addition
(n + m) = m + n                   commutative
((n + m) + k)=n + m + k           associative
0 = n + - n                       right inverse
0 = (- n) + n                     left inverse
n = - - n                         idempotent
(- n + m) = (- n) - m             negation distributes over addition
(*. / 0 &lt; n) implies 0 &lt; + / n    positive additivity
(*. / 0 &gt; n) implies 0 &gt; + / n    negative additivity
(n = m + k) implies m = n - k     left solvable
(n = m + k) implies k = n - m     right solvable
((n + m) = n + k) implies m = k   cancelation rule
(n = n + m) implies m = 0         unique right identity
(n = m + n) implies m = 0         unique left identity

Rules For Multiplication
(n * m) = m * n                   commutative
((n * m) * k) = n * m * k         associative
n = 1 * n                         identity
0 = 0 * n                         annihilator
(n * (m + k)) = (n * m) + n * k   left-distributive
((n + m) * k) = (n * k) + m * k   right-distributive
(- n) = _1 * n                    minus is multiplication by negative one
(- n * m)=(- n) * m               minus permutes over multiplication
(- n * m) = n * - m               minus permutes over multiplication
(n * m) = (- n) * - m
(n ^ k) = * / k #: n              exponentiation is iterated multiplication
(n ^ m + k) = (n ^ m) * n ^ k
(* / n ^ m) = n ^ + / m
(n ^ m ^ k) = n ^ m * k
(n ^ * / m) = ^ / n , m
((n + m) ^ 2) = (n ^ 2) + (2 * n * m) + m ^ 2
(*: n + m) = (*: n) + (+: n * m) + *: m
((n - m) ^ 2) = (n ^ 2) - (2 * n * m) + m ^ 2
(*: n - m) = (*: n) - (+: n * m) + *: m
((n + m) * n - m) = (n ^ 2) - m ^ 2
((n + m) * n - m) =(*: n) - *: m
n ((+ * -) = (*: [) - (*: ])) m

Even And Odd Integers; Divisibility
odd integers: 1 3 5 7 9 11 13 ..
even integers: 2 4 6 8 10 12 14 ..
'n is even' means n = 2 * m for some m with Z. m
'n is odd' means n = 1 + 2 * m for some m with Z. m
if E means even and I means odd then
 E = E + E and E = I + I
 I = E + I and I = I + E
 E = E * E and I = I * I
 E = I * E and E = E * I
 E = E ^ 2 and I = I ^ 2
 1 = _1 ^ E and _1 = _1 ^ I
n (-. |) m means "n divides m" if n = m * k for some integer k
n (-. |) n and 1 (-. |) n
"a is congruent to b modulo d" if a - b is divisible by d
if (a - b) | d and (x - y) | d then ((a + x) - b + y) | d 
if (a - b) | d and (x - y) | d then ((a * x) - b * y) | d

Rational Numbers
fractions: mrn with m , n integer numerals and -. n = 0 e.g. 0r1 _2r3 3r4 ...
dividing by zero does not give meaningful information
rational number line
(m % n) = s % t if *. / (-. 0 = n , t) , (m * t) = n * s
m = m % 1
(-. 0 = a , n) implies (m % n) = (a * m) % a * n  cancellation rule
(- m % n) = (- m) % n
(- m % n) = m % - n
(*. / (Q. r) , 0 &lt; r) iff *. / (r = n % m) , (Z. , 0 &lt;) n , m
"d is a common divisor of a and b" if d divides both a and b
the lowest form of a is mrn where 1 is the only common divisor of m and n
every positive rational has a lowest form
if -. n = 1 and the only common divisor of m and n is 1 then mrn = m % n
((a % d) + b % d) = (a + b) % d
((m % n) + a % b) = ((m * b) + a * n) % n * b
(0 = 0 % 1) and 0 = 0 % n
(a = 0 + a) and a = a + 0
negative rational numbers have the form _mrn
_mrn = - mrn and mrn = - _mrn
rational addition is commutative and associative
((m % n) * a % b) = (m * a) % n * b
((m % n) ^ k) = (m ^ k) % n ^ k
(Q. r) &lt;: -. 2 = r ^ 2
a real number that is not rational is called irrational
rational * is associative, commutative, and distributes over +
(Q. r) &lt;: (a = 1 * a) *. 0 = 0 * a
! = (* / 1 + i.) i.e. (! n) = 1 * 2 * 3 * ... * n
! = ] * (! &lt;:) i.e. (! 1 + n) = (1 + n) * ! n
(n ! m) = (! n + m) % (! n) * ! m   binomial coefficients
(n ! m) = ((! + /) % (* / !)) n , m   multinomial coefficients
(n ! m) = m ! n
(n ! m + 1) = (n ! m) + (n - 1) ! m
decimals

Multiplicative Inverses
(*. / (Q. a) , -. a = 0) implies *. / (Q. b) , 1 = a * b
"b is a multiplicative inverse of a" if *. / 1 = a (* ~ , *) b
(b = c) if *. / (-. 0 = a) , 1 = (a * b) , (b * a) , (a * c) , c * a
(-. 0 = a) implies *. / (1 = a * % a) , 1 = (% a) * a
(-. 0 = a =: n % m) implies *. / ((% a) = m % n) , (% a) = (n % m) ^ _1
(1 = a * b) implies b = a ^ _1
(0 = a * b) implies +. / 0 = a , b
((a % b) = c % d) if *. / (-. 0 = b , d) , (a * d) = b * c
(b = c) if *. / (-. 0 = a) , (a * b) = a * c   times cancellation law
(*. / -. 0 = b , c) implies ((a * b) % a * c) = b % c  quotient cancellation law
((a % b) + c % d) = ((a * d) + b * c) % b * d
((x ^ n) - 1) % x - 1) = (x ^ n - 1) + (x ^ n - 2) + ... + x + 1
if n is odd then (((x ^ n) + 1) % x + 1) = - ` + / x ^ n - 1 + i. n

Linear Equations

Equations In Two Unknowns
assuming c = (a * x) + b * y and u = (v * x) + w * y yields 
 x = ((w * c) - u * b) % (w * a) - v * b
 y = ((v * c) - w * u) % (v * b) - w * a
elimination method: common multiples

Equations In Three Unknowns
iterate elimination method

Real Numbers

Addition And Multiplication
the real number line
addition of real numbers is commutative, associative, a = 0 + a , 0 = a + - a
(0 = a + b) implies b = - a  unique additive inverse
* is commutative,associative,distributes over +, a = 1 * a, 0 = 0 * a
((a + b) ^ 2) = (a ^ 2) + (2 * a * b) + b ^ 2
((a - b) ^ 2) = (a ^ 2) - (2 * a * b) + b ^ 2
((a + b) * a - b) = (a ^ 2) - b ^ 2
every nonzero real number has a unique multiplicative inverse
the E , I system satisfies the addition and multiplication properties

Real Numbers: Positivity
positivity as being on a side of 0 on the number line
a &gt; 0 means "a is positive"
(*. / 0 &lt; a , b) implies *. / 0 &lt; (a * b) , a + b
(*. / 0 &lt; a) implies (*. / 0 &lt; * / , + /) a
~: / (0 = a) , (0 &lt; a) , 0 &gt; - a
a &lt; 0 means -. *. / (0 = a) , (- a) &gt; 0
"a is negative" means a&lt;0
(a &lt; 0) iff 0 &lt; - a
(0 &lt; 1) and 0 &gt; _1
every positive integer is positive
(0 &gt; a * b) if (0 &lt; a) and 0 &gt; b
(0 &gt; a * b) if (0 &gt; a) and 0 &lt; b
(0 &lt; a) implies 0 &lt; 1 % a
(0 &gt; a) implies 0 &gt; 1 % a
assume completeness: (a &gt; 0) implies *. / (0 &lt; %: a) , a = (%: a) ^ 2
"the square root of a" means %: a
an irrational number is a real number that is not rational e.g. %: 2
Assuming *. / a = *: b , x yields
 0 = - / *: b , x
 0 = x (+ * -) b
 +. / 0 = x (+ , -) b
 +. / x = (- , ]) b
((x ^ 2) = y ^ 2) implies (x = y) or x = - y
(| x) = %: *: x  absolute value
(% (%: x + h) + %: x) = ((%: x + h) - %: x) % h  rationalize 
0 &lt; a ^ 2
(%: a % b) = (%: a) % %: b alternatively ((%: % /) = (% / %:)) a , b
(*. / (Q. x , y , z , w) , (N. *. 0 &lt;) n) implies (
*. / (Q. c , d) , (c + (d * %: n)) = (x + y * %: n) * z + w * %: n
(| a - b) = | b - a

Powers And Roots
assume *. / (0 &lt; a) , (N. , 0 &lt; ) n implies a = (n %: a) ^ n for a unique n %: a
"the nth-root of a" means n %: a
(a ^ 1 % n) = n %: a
(0 &lt; a , b) implies ((n %: a) * n %: b) = n %: a * b
fractional powers: *. / (Q. x) , 0 &lt; a implies there exists a ^ x such that
((a ^ x) = a ^ n) if x = n
((a ^ x) = n %: a) if x = 1 % n
(a ^ x + y) = (a ^ x) * a ^ y
(a ^ x * y) = (a ^ x) ^ y
((a * b) ^ x) = (a ^ x) * b ^ x
*. / (1 = a ^ 0) , 1 = * / #: 0
(a ^ - x) = 1 % a ^ x
(a ^ m % n) = (a ^ m) ^ 1 % n
(a ^ m % n) = (a ^ 1 % n) ^ m

Inequalities
a &lt; b means 0 &lt; b - a
a &lt; 0 means 0 &lt; - a
a &lt; b means b &gt; a
inequalities on the numberline
a &lt;: b means a &lt; b or a = b
a &gt;: b means a &gt; b or a = b
(*. / (a &lt; b) , b &lt; c) implies a &lt; c
(*. / (a &lt; b) , 0 &lt; c) implies (a * c) &lt; b * c
(*. / (a &lt; b) , c &lt; 0) implies (b * c) &lt; a * c
x is in the open interval a , b if (a &lt; *. b &gt;) x
x is in the closed interval a,b if (a &lt;: *. b &gt;:) x
x is in a clopen interval a,b if +. / ((a &lt; *. b &gt;:) , (a &lt;: *. b &gt;)) x
(a &lt;),(a &lt;:) , (a &gt;) , a &gt;:  infinite intervals
intervals and the numberline
(*. / (0 &lt; a) , (a &lt; b) , (0 &lt; c) , c &lt; d) implies (a * c) &lt; b * d
(*. / (a &lt; b) , (b &lt; 0) , (c &lt; d) , d &lt; 0) implies (a * c) &gt; b * d
(*. / (0 &lt; x) , x &lt; y) implies (1 % y) &lt; 1 % x
(*. / (0 &lt; b) , (0 &lt; d) , (a % b) &lt; c % d) implies (a * d) &lt; b * c
(a &lt; c) implies ((a + c) &lt; b + c) and (a - c) &lt; b - c
(*. / (0 &lt; a) , a &lt; b) implies (a ^ n) &lt; b ^ n
(*. / (0 &lt; a) , a &lt; b) implies (a ^ 1 % n) &lt; b ^ 1 % n
(*. / (0 &lt; b , d) , (a % b) &lt; c % d) implies ((a % b) &lt; (a + c) % b + d)
(*. / (0 &lt; b , d) , (a % b) &lt; c % d) implies ((a + c) % b + d) &lt; c % d)
(*. / (0 &lt; b , d , r) , (a % b) &lt; c % d) implies (
 (a % b) &lt; (a + r * c) % b + r * d)
(*. / (0 &lt; b , d , r) , (a % b) &lt; c % d) implies (
 ((a + r * c) % b + r * d) &lt; c % d)
(*. / (0 &lt; b , d , r) , (r &lt; s) , (a % b) &lt; c % d) implies (
((a + r * c) % b + r * d) &lt; (a + s * c) % b + s * d)

Quadratic Equations
((*. / 
 (-. a = 0) , 
 (0 = (a * x ^ 2) + (b * x) + c) , 
 (0 &lt;: (b ^ 2) - 4 * a * c)) 
implies
+. / 
 (x = (- b + %: (b ^ 2) - 4 * a * c) % 2 * a) , 
 (x = (- b - %: (b ^ 2) - 4 * a * c) % 2 * a))
(0 &gt; (b ^ 2) - 4 * a * c) implies -. *. / (R. x) , 0 = (a * x ^ 2) + (b * x) + c

On Logic And Mathematical Expressions

Logic
proof as list of statements each either assumed or derived from a deduction rule
converse: the converse of "if A, then B" is "if B, then A"
"A iff B" means "if A, then B" and "if B, then A"
proof by contradiction: take A false, derive a contradiction, conclude A true
equations are not complete sentences
logical equivalence as A iff B

Sets And Elements
set: a collection of objects
element: an object in a set
subset: s0 is a subset of s1 if every element of s0 is an element of s1
empty set: a set that does not have any elements
set equality: s0 equals s1 if s0 is a subset of s1 and s1 is a subset of s0.

Indices
"let x,y be something" includes the possibility that x=y
"let x,y be distinct somethings" excludes the possibility that x=y
x0 x1 x2 x3 .. xn is a finite sequence

Distance And Angles

Distances
assume p0 d p1 gives the distance between the points p0 , p1
assume that for any points p0,p1,p2
0 &lt;: p0 d p1   nonnegative
(0 = p0 d p1) iff p0 = p1   nondegenerate
(p0 d p1) = p1 d p0   symmetric
(p0 d p1) &lt;: (p0 d p2) + p2 d p1   triangle inequality
note the geometric meaning of the triangle inequality
the length of a side of a triangle is at most the sum of the others
assume that two distinct points lie on one and only one line
 (-. p0 = p1) implies *. / (p0 p1 i p0 , p1),
 (*. / p2 p3 i p0 , p1) implies p2 p3 i = p0 p1 i
define betweenness as equality case of the triangle inequality
 (p0 p1 B p2) iff (p0 d p1) = (p0 d p2) + p1 d p2
define segment as the points between a pair of endpoints
 (p0 p1 W p2) iff p0 p1 B p2  (by definition of B we have p0 p1 i p2)
assume the length of a segment is the distance between its endpoints
 (mW p0 p1) = p0 d p1
assume rulers pick out unique points
 (*./(0&lt;:a),a&lt;:p0 d p1) implies *./(p0 p1 W p2),a=p0 d p2 for some p2
 ((*./(p0 p1 W),(= p0 d))p2,p3) implies p2=p3
define circle as the points equidistant from a common point
 (p0 p1 o p2) if (p0 d p1)=p0 d p2  geometric circle from metric
define (p0 r bdB) as the circle with center p0 and radius r
 (p0 r bdB p1) if r=p0 d p1  metric circle as boundary of a ball
prove two points uniquely define a circles
 (p0 p1 o p2) implies (p0 p1 o = p0 p2)
prove a point and radius uniquely define a circle
 (p0 r bdB p1) implies (p0 r bdB p2) iff p0 p1 o p2
define (p0 r clB p1) as the disc with center p0 and radius r
 (p0 r clB p1) if r&gt;:p0 d p1

Angles
assume distinct points lie on a unique line
 (-.p0=p1) implies *./(p0 p1 i p0,p1),
 (*./p2 p3 i p0,p1) implies (p2 p3 i = p0 p1 i)
assume a pair of nonparallel lines share a unique point
 (-.p0 p1 p2 H p3) implies (p0 p1 i *. p2 p3 i)p4 for some p4
 (*./(-.p0 p1 p2 H p3),(p0 p1 i *. p2 p3 i)p4,p5) implies p4=p5
assume a point belongs to a unique parallel to a line
 p0 p1 p2 H p2
 (*./(p0 p1 p2 H p3),p2 p3 i p4) implies p0 p1 p2 H p4
 (*./p0 p1 p2 H p3,p4) implies (p2 p3 i = p2 p4 i)
assume "parallel to" is an equivalence relation
 p0 p1 p0 H p1
 (p0 p1 p2 H p3) implies p2 p3 p0 H p1
 (*./(p0 p1 p2 H p3),p0 p1 p4 H p5) implies p2 p3 p4 H p5
assume a point belongs to a unique perpendicular to a line
 (*./(p0 p1 p2 L p3),p2 p3 i p4) implies p0 p1 p2 L p4
 (*./p0 p1 p2 L p3,p4) implies (p2 p3 i = p2 p4 i)
assume a parallel to a perpendicular is perpendicular
 (*./(p0 p1 p2 L p3),p2 p3 p4 H p5) implies p0 p1 p4 L p5
assume a perpendicular to a perpendicular is parallel
 (*./(p0 p1 p2 L p3),p2 p3 p4 L p5) implies p0 p1 p4 H p5
define a halfline as points on the same side of a line relative to a vertex
 (p0 p1 R p2) if (p2 B p0 p1)+.p1 B p0 p2
assume a halfline is determined by its vertex and any other point on it
 ((p0 p1 R p2)*.-.p0=p2) implies p0 p1 R = p0 p2 R
define (p0 p1 R) as the halfline with vertex p0 to which p1 is incident
assume a pair of distinct points determine two distinct rays
 (-.p0=p1)&lt;:p0 p1 R (-.=) p1 p0 R
assume a point on a line divides it into two distinct halflines
 (p0 p1 i p2)&lt;: (p0 p1 R p2)+.(p0 p1 i p3) implies (p0 p1 R p3)+.p0 p2 R p3
assume two distinct halflines sharing a vertex separate the plane into two parts
define angle as one of the parts of the plane separated by such halflines
assume two points on a circle divide it into two distinct arcs
note Lang uses counterclockwise oriented angles rather than neutral angles
assume p0 p1 p2 c is the counterclockwise arc of (p1 p0 o) from p0 to (p1 p2 R)
define (p0 p1 p2 V) as the angle from p1 p0 R to p1 p2 R containing p0 p1 p2 c
define the vertex of (p0 p1 p2 V) as p1
define (p0 p1 p2 V) is a zero angle as (p1 p0 R = p1 p2 R)
define (p0 p1 p2 V) is a full angle as (p2 p1 p0 V) is a zero angle
note special notation to distinguish a full angle from a zero angle
define (p0 p1 p2 V) is a straight angle as (p0 p1 i p2)
prove if (p0 p1 p2 V) is a straight angle then so is (p2 p1 p0V)
define (p0 p1 p2 r clBV) as the sector of (p1 r clB) determined by (p0 p1 p2 V)
 (p0 p1 p2 r clBV p3) if (p1 r clB p3)*.(p0 p1 p2 V p3)
define mclB p0 r as the measure of the area of (p0 r clB)
define mclBV p0 p1 p2 r as the the measure of the area of (p0 p1 p2 r clBV)
define (mV p0 p1 p2) using the ratio (mclBV p0 p1 p2 r) to mclB p1 r
 (mV p0 p1 p2)=x deg if *./(0&lt;:x),(x&lt;:360),((mclBV p0 p1 p2 r)%mclB p0 r)=x%360
define "x deg" as "x degrees"
prove the measure of a full angle is 360 deg
 (p0 p1 R p2) implies (360 deg)= mV p2 p1 p0
prove the measure of a zero angle is 0 deg
prove the measure of a straight angle is 180 deg
define a right angle as one whose measure is half a straight angle i.e. 90 deg
 (p0 p1 p2 V) is right iff 90=mV p0 p1 p2
assume the area of a disc of radius r is pi*r^2 where pi is near 3.14159
prove that the measure of an angle is independent of r

Pythagorean Theorem
define p W p0 as +. / 2 (p0 W ~) \ p
define noncolinear points p0,p1,p2 as -. p0 p1 i p2
define triangle as segments between three points
 (p0 p1 p2 A p3) if p0 p1 p2 p0 W p3
define the triangle with vertices p0 , p1 , p2 as (p0 p1 p2 A)
define the sides of (p0 p1 p2 A) as (p0 p1 W), (p1 p2 W), and (p2 p0 W)
define triangular region as the points bounded by and having a triangle
define area of a triangle as area of a triangular region
define mA p0 p1 p2 as the measure of the area of (p0 p1 p2 A)
note triangular regions are also called simplexes
note pairs of sides of a triangle determine angles
define a right triangle as one having a right angle
 (p0 p1 p1 p2 Z p3) if *./ (p0 p1 p2 A p3) , 90 = mV p1 p2 p0
define the legs of a right triangle as the sides of its right angle
define the hypotenuse of a right triangle as the non-leg side
assume right triangles with corresponding legs of equal length are congruent
 (*./(p0 p1 p2 Z),(p3 p4 p5 Z),((p1 d p2)=p4 d p5),(p2 d p0)=p5 d p3) implies
 *./((mV p0 p1 p2)=mV p3 p4 p5),((mV p1 p0 p2)=mV p4 p3 p5),
 ((p0 d p1)=p3 d p4),(mA p0 p1 p2)=mA p3 p4 p5
assume parallels perpendicular to parallels cut corresponding segments equally
 (*./(p0 p1 p2 H p3),(p0 p1 p0 L p2),p0 p1 p1 L p3) implies 
 *./((p0 d p1)=p2 d p3),(p1 d p2)= p3 d p0
define (0=mH p0 p1 p2 p3) if -.(p0 p1 p2 H p3)
define ((p0 d p1)=mH p2 p0 p3 p1) if p2 p0 p3 H p1
prove the distance between parallel lines is unique
(*./(p0 p1 p2 H p3, p4)(p2 p3 p3 L p5)(p0 p1 i p5,p6)p2 p4 p4 L p6)&lt;:(p3 d p5)=p4 d p6
define rectangle as four sides: opposites parallel and adjacents perpendicular
 (p0 p1 p2 p3 Z p4) if 
 *. / (p0 p1 p2 H p3) , (p1 p2 p3 H p0) ,
 (p0 p1 p1 L p2) , (p1 p2 p2 L p3) , (p2 p3 p3 L p0) , (p3 p0 p0 L p1) ,
 p0 p1 p2 p3 p0 W p4
define (p0 p1 p2 p3 Z) as a rectangle with vertices p0 p1 p2 p3
prove the opposite sides of a rectangle have the same length
note area of a rectangle means area of region bounded and containing a rectangle
define (mZ p0 p1 p2 p3) as area of (p0 p1 p2 p3 Z)
define a square as a rectangle all of whose sides have the same length
prove the area of a square with side length a is a ^ 2
prove that (p0 p0 p1 p2 Z) uniquely determines (p3 p0 p1 p2 Z)
prove the sum of the non-right angles in a right triangle is 90 deg
 (p0 p0 p1 p2 Z) implies 90 = (mV p1 p0 p2) + mV p1 p2 p0
prove the sum of the angles in a right triangle is 180 deg
 (p0 p0 p1 p2 Z) implies 180 = (mV p0 p1 p2) + (mV p1 p2 p0) + mV p2 p0 p1
prove the area of a right triangle with leg lengths a,b is -: a * b
prove the Pythagorean theorem
 (p0 p1 p1 L p2) implies (*: p0 d p2) = + / *: (p0 d p1) , (p1 d p2)
prove a triangle is right iff it satisfies the pythagorean theorem
define the diagonals of (p0 p1 p2 p3 Z) as (p0 p2 W) and p1 p3 W
prove the lengths of the diagonals of a rectangle (and square) are the same
prove the length of the diagonal of a square with side length 1 is %: 2
prove a right triangle with legs of length 3,4 has hypotenuse of length 5
define perpendicular bisector as line perpendicular to segment through midpoint
 (p0 p1 t p2) if ((-: p0 d p1) = p0 d p3) implies +. / (p2 = p3) , p0 p3 p3 L p2
prove (p0 p1 t p2) iff (p0 d p2) = p1 d p2
prove the *: of the diagonal of a rectangular solid is + / *: of its sides
prove the area of a triangle with base length b and height h is -: b * h
prove the hypotenuse of a right triangle is greater than or equal to a leg
prove (*. / (p0 p1 p2 L p3) , (p0 p1 i p3 , p4)) implies (p2 d p3) &lt;: p2 d p4
prove opposite interior angles are the same
prove corresponding angles are the same
prove opposite angles are the same
prove the perpendicular bisectors of the sides of a triangle meet at a point

Isometries

Some Standard Mappings Of The Plane
define p0 is mapped to p1 as (p0 ; p1)
note map is similar in meaning to association,function,verb,arrow
define map of the plane as associating each point of the plane with another
define the value of M0 at p0 or the image of p0 under M0 as (M0 p0)
define M0 maps p0 onto p1 as p1 = M0 p2
define (M0 = M1) as (M0 p0) = M1 p0 for all p0
define the p0 constant map as (p0 Mp)
 p0 = p0 Mp p1
note (p0 [) is the constant map
 p0 = (p0 [ p1)
define the identity map as ]
 p0 = ] p0
note ] is the identity map
 p0 = ] p0
define the reflection map about (p0 p1 i) as (p0 p1 Mt)
 p0 = p1 p2 Mt p3 if (p1 p2 i p4) iff p0 p3 t p4
define the reflection map about p0 as Mm
 (p0 = p1 Mm p2) if p0 p2 m p1
define the dilation about p0 of p1 to p2 as (p0 p1 p2 MH)
 (p0 = p1 p2 p3 MH p4) if
 (*. / (p3 p1 p1 L p5,p6)(p1 p2 o p5)(p1 p3 o p6))&lt;:(p3 p5 p6 H p4)*.p0 p3 i p4
define dilation by r0 about p0 as (p0 r0 IH)
 (p0 = p1 r0 IH p2) if (p1 d p2)=r*p1 d p0
define the counterclockwise rotation about p1 by (p0 p1 p2 V) as (p0 p1 p2 Mo)
 (p0 = p1 p2 p3 Mo p4) if 
 (*./(p2 p4 o p5)(p2 p1 i p5)(p2 p3 i p6)(p2 p6 p6 L p1)p5 p6 Ed p4 p7)&lt;:
 (p2 p4 o p0)*.p2 p7 i p0
note the rotation map defined assumes acute angles
define the counterclockwise rotation about p0 by r0 degrees as (p0 r0 Io)
 (p0 = p1 r0 Io p2) if *./(0&lt;:r0)(r0&lt;:360)r0=mV p2 p1 p0
note 0&lt;:r0 implies (p0 r0 Io) is c.c. and r0&lt;:0 implies (p0 r0 Io) is clockwise
prove p0 180 Io = p0 Mm
prove p0 180 Io = p0 _180 Io
prove (p0 0 Io = ])
prove (p0 360 Io = ])
note rotation by 0 or 360 degrees is the identity transformation
define (p0 r0 oV) as (p0 r1 oV) with *./(0&lt;:r1),(r1&lt;360),r0=r1+360*n for some n
prove rotation by a negative angle is rotation by a positive angle
define the arrow from p0 to p1 as a0 =: p0 ; p1
 ((p0 S a0) *. p0 T a0) if a0 = p0 ; p1
define p0 is an object of a0 if p0 S a0 or p0 T a0
 (p0 O a0) if (p0 S a0) +. p0 T a0
note, in general, a0;a1 is an arrow with objects a0,a1, source a0 and target a1
 *. / ((a0 , a1) O a0 ; a1) , (a0 S a0 ; a1) , a1 T a0 ; a1
define p0 p1 W as the directed line segment associated with the arrow p0;p1
 (p0 p1 W = p1 p0 W) iff p0 = p1
define translation by (p0 p1 W) as (p0 p1 MW)
 (p0 = p1 p2 MW p3) if
 ((p1 p3 p3 L p0) *. p1 p3 p2 H p0) +.
 *. / ((p1 p2 i p3)(-.p1 p2 i p4)(p1 p4 p2 H p5)p4 p5 p1 H p2)&lt;:p0=p4 p5 MW p3
define p0 is a fixed point of M0 if p0 = M p0
prove that every point is a fixed point of ]
prove that p0 is the only fixed point of p0 Mp
prove p0 is the only fixed point of p0 Mm
prove p0 is a fixed point of (p1 p2 Mt) iff (p1 p2 i p0)
prove (-. 0 = mV p0 p1 p2) implies p1 is the only fixed point of p0 p1 p2 MV
prove (-. 0 = r0) implies p0 is the only fixed point of p0 r0 IV
prove that (-. p0 = p1) implies (p0 p1 MW) has no fixed points
prove if -. 1 = r0 implies p0 is the only fixed point of p0 r0 IH
prove every point is a fixed point of p0 1 IH

Isometries
define M0 is an isometry if it preserves distance: (d=d I0)
 (p0 d p1) = (I0 p0) d I0 p1
prove isometries map distinct points to distinct points
 (-. p0 = p1) implies -. (M0 p0) = M0 p1
define y is in the image of A under M0 if y = M0 x for some x in A
assume point and line reflects, rotations, and translations are isometries
prove isometries of points are points
prove isometries of line segments are line segments
prove isometries of lines are lines
prove isometries of circles are circles
prove isometries of discs are discs
prove isometries of circular arcs are circular arcs
prove if -. p0 = p1 fixed points of an isometry then so are points on p0 p1 i
prove an isometry wit three fixed points is the identity
prove (p0 1 IH) and (p0 _1 IH) are isometries (the only of the family IH)
prove isometries of parallel lines are parallel
prove isometries of perpendiculars are perpendicular
note isometries in 3 space

Composition of isometries
define the composition of M0 with M1, M1 followed by M0, as (M1 M0)
 (p0 = (M0 M1) p1) if (p2 = M1 p1) implies p0 = M0 p2
prove if M0 is an isometry then M0 = (] M0) and M0 = (M0 ])
prove the composition of two (p0 180 Io) is ]
prove the composition of isometries is an isometry
prove the composition of rotations about a point is a rotation about that point
 p0 (r0 + r1) Io = (p0 r1 Io p0 r0 Io)
prove that the composition of translations is a translation
 p0 p2 MW = (p1 p2 MW p0 p1 MW)
prove the composition of dilations about a point is a dilation about that point
 p0 (r0 * r1) IH = (p0 r1 IH p0 r0 IH)
prove the composition of isometries is associative (arrows in general)
define (M0 ^: 2) as (M0 M0)
define (M0 ^: 3) as (M0 M0 M0)
define (M0 ^: 1 + n) as (M0 M0^:n)
define (M0 ^: 0) as ] and (M0^:1) as M0
prove MI = (p0 Mm) ^: 2
prove MI = (p0 Mm) ^: 2 * n
prove (p0 Mm) = (p0 Mm) ^: 1 + 2 * n
prove (M0 ^: n0 + n1) = (M0 ^: n0 M0 ^: n1)
prove if M0 is a reflection through a line then (M0 ^: 2) is MI
note not all isometries commute

Inverse Isometries
define M0 as the inverse of M1 if (] = (M0 M1)) and (] = (M1 M0))
prove the inverse of a map is unique if it has one
define (M0 ^: _1) as the inverse of M0 if it has one
note (y = M0 x) iff (x = (M0 ^: _1)y) or ([ = (M0 ])) = (] = ((M0 ^: _1) [))
prove reflections are their own inverses
prove identity is its own inverse
prove ] = (p0 p1 MW p1 p0 MW) and ] = (p1 p0 MW p0 p1 MW)
prove (p0 p1 MW) and (p1 p0 MW) are inverses of each other
prove ] = (p0 r0 Io p0 -r0 Io) and ] = (p0 -r0 Io p0 r0 Io)
prove (p0 r0 Io) and (p0 -r0 Io) are inverses of each other
 (p0 -r0 Io) = (p0 r0 Io) ^: _1
prove ((M0 M1) ^: _1) = (M1 ^: _1 M0 ^: _1)
define M0 ^: _n0 as (M0 ^: _1) ^: n0
prove (M0 ^: n0 + n1) = (M0 ^: n0) M0 ^: n1
prove if M0,M1 are isometries *./(M0=M1)p0,p1,p2 then (M0=M1) if M0^:_1 exists
prove every isometry actually does have an inverse
prove reflections about perpendicular lines commute
prove M0 , M1 , M2 isometries (M0 M1) = (M0 M2) implies M1 = M2
note symmetries of the square via isometries
note symmetries of the triangle via isometries
note symmetries of the hexagon via isometries
note do these isometric symmetries characterize these shapes?

Characterization Of Isometries
prove -. p0 = p1 fixed points of isometry M0 implies +. / (MI = M0) , p0 p1 MT = M0
prove an isometry with only one fixed point is +. / Mo , Mo MT
prove an isometry without a fixed point is +. / MW , (MW Mo) , ((MW Mo) Mm)

Congruences
define p00,p01,..,p0n is congruent to p10,p11,..,p1m if p00,..,p0n=M0 p11,..,p0m
note if one set is the image of another under an isometry then they're congruent
prove circles with the same radius are congruent
prove discs with the same radius are congruent
prove segments with the same length are congruent
prove right triangles whose corresponding legs are congruent are congruent
prove triangles whose corresponding sides are congruent are congruent
prove squares whose sides are congruent are congruent
prove rectangles whose corresponding sides are congruent are congruent
assume the area of a region is equal to the area of its image under an isometry
prove congruence is an equivalence relation
prove any two lines are congruent
prove the sides of a triangle with angle measures 60 deg have equal length
define equilateral triangle if its sides are all the same length
prove SAS characterization of congruence
prove AAS characterization of congruence
prove inscribed circle in a triangle angle bisectors

Area And Applications

Area Of A Disc Of Radius r
note a unit length determines a unit area
assume area of a square with side length a is a^2
assume area of a rectangle with side lengths a,b is a*b
prove the area of the dilation by r of a square of area a is a*r^2
assume the area of the dilation by r of a region with area a is a*r^2
define o.1 as the length of of a circle with radius 1
prove the area of the dilation by r of a disc of radius 1 is o.-:r^2
note approximate regions with squares to find their area
note upper/lower bounds as areas inside and outside of figure
define ellipse as nonuniform scaling of a disc
prove map circle to ellipse algebraically
note scaling and volume in 3-space is similar

Circumference Of A Circle Of Radius r
assume ((o. 1) = mbdB p0 1) and (o. r) = mbdB p0 r
note approximate by dividing disc into n sectors with angles 360%n
note disc area to circle length
prove the length of the dilation by r of a segment of length a is r*a
assume the length of the dilation by r of an arbitrary curve of length a is r*a

Coordinates And Geometry

Coordinate Systems
define an origin as the intersection of perpendicular lines (called axis)
note the classical origin is the intersection of a horizontal and vertical line
note pick unit length, cut axes into segments left/right up/down
note cut plane into squares with unit side lengths
note label each point of intersection with a pair of integers
note intersection of perpendicular lines to axes through a point gives its coordinate
define the coordinate of the origin as 0,0
note meaning of the positive/negative components as motions
define x-coordinate is usually the first, y-coordinate is usually the second
prove the axes divide the plane into four quadrants
define the positive side of the second axis as counterclockwise the first
note plot points
assume/prove every point corresponds to a unique pair of numbers
assume/prove every pair of numbers corresponds to a unique point
note points in 3-space

Distance Between Points
points on the number line are labeled so that algebraic definitions work simply
note the distance between points in the plane is found using the pythagorean theorem
prove the distance between points p0 and p1 on a number line is %:(p0-p1)^2
 (*./(p0=a0,b0),p1=a1,b1) implies (p0 d p1)=%:@+/@*:(a1-a0),(b1-b0)
assume distance as d=:%:@+/@*:- satisfies the required geometric properties
define the plane as all pairs of real numbers with distance %:@+/@*:-
prove (0 = p0 d p1) iff p0 = p1
define dilation as * i.e. (r * x , y) = (r * x) , r * y
prove (0 &lt;: r) implies (d r * x , y) = r * d x , y 
prove ((r * [) d r * ]) = r * d
prove distance works in 3-space

Equation Of A Circle
assume (p0 p1 o p2) iff (p0 d p1) = p0 d p2
assume p0 r0 bdB p1 if r0 = p0 d p1
define p0 r0 bdB as the circle centered at p0 with radius r0
prove ((p0=:r0,r1) r2 bdB p1=:r3,r4) iff (*:r0)=+/*:p0-p1
prove is the equation of a circle in r3,r4 with center r1,r2 and radius r0 is
 (*: r0) = + / *: (r1 , r2) - r3 , r4
prove (p0 r0 bdB p1) iff (*: r0) = + / *: p0 - p1

Rational Points On A Circle
prove ((*:c)=+/*:a,b) iff (1=+/*:(a,b)%c) iff 1=+/*:(x=:a%c),(y=:b%c) when -.c=0
note to solve (*:c)=+/*:a," for integers a,b,c solve 1=+/*:x,y for rationals x,y
define a rational point as one whose components are rational numbers
prove (*./(t=:y%1+x),(1=+/*:x,y),-._1=x) &lt;: *./x=((1- % 1+)*:t),y=(2* %(1+*:))t
prove 1=+/*:x,y rational &lt;: *./x=(1- % 1+)*:t),y=((2*)%(1+*:))t for rational t
prove distinct rationals give distinct solutions
 (*./(0&lt;:s),s&lt;t) implies &lt;/((1-)%(1+))*:s,t

Operations On Points

Dilations And Reflections
assume (r0*r1,r2)=(r0*r1),r0*r2
prove (p0= p1 r0 IH p2) iff (p0=p1+r0*p2-p1) or (p0=(r0*p2)+(1-r0)*p1)
prove (p0= p1 Mm p2) iff (p0=p1-p2-p1) or (p0=(+:p1)-p2)
prove ((r0*r1)d r0*r2)=(|r0)* r1 d r2
note the n-dimensional case

Addition Subtraction And The Parallelogram Law
assume ((a0,a1)+b0,b1)=(a0+b0),a1+b1
prove commutativity (p0+p1)=p1+p0
prove associativity: (p0+p1+p2)=(p0+p1)+p2
prove 0,0 is an additive identity: (p0=p0+0,0) and p0=(0,0)+p0
prove additive inverses exist: ((0,0)=p0+-p0) and (0,0)=(-p0)+p0
prove the points (0,0);p0;p1;p0+p1 are vertices of a parallelogram
 (0,0),p0,p1,:p0+p1 W is a parallelogram
prove p0=(p0-p1)+p1
prove (0,0);p0;p1;p0-p1 are vertices of a parallelogram
prove (p0=p1 p2 MW p3) iff (p0=p1+(p2-p1)+p3-p1) or p0=p3+p2-p1
define norm p0 as (0,0) d p0
 norm =:(0,0) d
prove (p0 d p1)=norm p0-p1
prove (p0 d p1)=norm p1-p0
prove M0 is an isometry iff (norm p0-p1)=norm (M0 p0)-M0 p1
prove (p0 r0 bdB p1) iff (p1=(0,0) p0 MW p2) for some p2 with r0=norm p1 p2
prove every circle is the translation of a circle about the origin
 (p0 r0 bdB p1) iff (p1=(0,0) p0 MW p2) for some p2 with (0,0) r0 bdB p2
prove associativity: (r0*r1*p0)=(r0*r1)*p0
prove distributivity: (r0*p0+p1)=(r0*p0)+r0*p0
prove identity: p0=1*p0
prove annihilator: (0,0)=0*p0
prove translation is an isometry
 (p0 d p1)=(p2 p3 MW p0) d p2 p3 MW p1
prove a reflection through the origin followed by a translation is a point-reflection
 (p0 p1 MW (0,0) Mm)= p2 Mm for some p2
prove a dilation through the origin followed by a translation is a point-dilation
 (p0 p1 MW (0,0) r0 MH)= p2 r1  MH for some p2 and r1
prove the reflection of a circle through a point is a circle
for some p4,p5 (*./(p0=p1 Mm p2),p3 p4 o p2) iff (p4 p5 o p0)
prove the dilation of a circle through a point is a circle
prove ((]=(M0 p0 p1 MW) and ]=p0 p1 MW M0) iff (M0 p2)=p0+(p0-p1)+p2-p0
prove the inverse of a translation is a translation
prove ((]=M0 p0 r0 IH) and ]=p0 r IH M0) iff (M0 p1)=p0+(%r)*p1-p0
prove the inverse of a dilation is a dilation
prove (p0 = p1 p2 MW p0) iff (p0=p0+p2-p1) iff ((0,0)=p2-p1) iff p1=p2
prove translation doesn't have fixed points unless it is the identity
prove the fixed points of a transformation via its coordinate definition
prove (*./(p0=a0,a1),(e0=1,0),e1=0,1) implies p0=(a0*e0)+a1*e1
prove p0,(p0+r*e0),(p0+r*e1),:(p0+(r*e0)+r*e1) W is a rectangle

Segments, Rays, And Lines

Segments
prove (p0 p1 W p2) iff *./(p2=p0+(p1-p0)*t),(0&lt;:t),t&lt;:1
prove the point halfway between p0 and p0+p1 is p0+-:p1
prove every segment is a translation of a segment from the origin
prove every segment is a translation of a dilation of a unit segment from the origin
prove (p0 p1 W p2) iff *./(p2=((1-t)*p0)+t*p1),(0&lt;:t),t&lt;:1
assume (p0 p1 W) is a directed segment ordered by ((1-t)*p0)+t*p1 with 0&lt;:t and t&lt;:1
note p0 p1 W is also called a located vector
define the source of p0 p1 W as p0
define the target of p0 p1 W as p1
note p0 p1 W is also said to be located at p0
prove (p0 p1 MW = p1 p0 MW) iff p0=p1
note a point can be represented as an arrow whose source and target are equal

Rays
define the ray with vertex p0 in the direction of (0,0) p1 W as p0 (p0 + p1) R
prove p0 p1 R p2 iff *. / (p2 = p0 + t * p1 - p0) , (R. *. 0 &lt;:) t for some t
prove p0 p1 R = p0 (p1 - p0) R
prove (R. *. 0 &lt;)t implies p0 p1 R = p0 (t * p1) R
define p0 p1 R has the same direction as p2 p3 R if 
 *. / ((R. *. 0 &lt;:) t) , (p1 - p0) = t * p3 - p2 
note this induces a sensed parallel axiom
note multidimensional forms

Lines
define p0 p1 W is parallel to p2 p3 W if *. / (R. t) , (p1 - p0) = r * p3 - p2
prove parallelism in this way is an equivalence relation
define p0 parallel to p1 if *. / (-. 0 = p0 , p1) , (R. t) , p0 = t * p1 for some t
prove a located vector belongs to a unique line
 p0 p1 W p2 implies p0 p1 i p2
prove (-.p0=0,0) implies ((0,0),:p0 i p1) iff p1=t*p0 for some t
note the line passing through p0 parallel to (0,0) p1 W is all points p0+t*p1 for some t
prove p0 p1 i p2 iff p2=p0+t*p1 for some t
note p0+t*p1 is called a parametric representation of the line i p0 (p0+p1)
note in N the parametric representation is actually p0 + p1 *
note t is called a parameter in p0+t*p1
note the following argument in N
 p0 =: a0 , a1   p0 is the ordered pair a0,a1
 p1 =: b0 , b1   p1 is the ordered pair b0,b1
 p =: p0 + p1 *   parametric description of the line through p0 parallel to p1
 x =: 0 { p   zeroth coordinate of p
 y =: 1 { p   first coordinate of p
 p = (x , y)
 x = a0 + b0 *
 y = a1 + b1 *
 xaxis =: 0 , ~
 p = xaxis x  suppose p is equal to a point on the xaxis
 (x , y) = 0 , ~ x p = (x , y) and (x , 0) = xaxis x
 (x = x) *. 0 = y   pairs are equal iff their components are
 x = x   this is always true, so we don't get any new information
 0 = y   thus (p=xaxis x) iff (0=y)
 (0 = y) t   does there exist t such that 1=((0=y)t) ?
 (0 = a1 + b1 *) t
 (0 t) = (a1 + b1 *) t
 0 = a1 + b1 * t
 t =: b1 % ~ s
 0 = a1 + b1 * b1 % ~ s
 0 = (a1 +) ] s   by algebra 1=]*(%]) or (-.0=[)&lt;: ]=[ * ] % [
 0 = a1 + s
 s =: (- a1) + u
 0 = a1 + (- a1) + u
 0 = ] u
 0 = u
 t = b1 % ~ (- a1) + 0
 t = b1 % ~ (- a1)
 t = (- a1) % b1
 t = - a1 % b1
   p - a1 % b1   yields a point on the x-axis, it is unique (by other arguments)
note mW O p0 can be used to represent the magnitude of a velocity (speed)
note when do two parametrically described lines intersect?
prove when a line crosses a circle
for what x and y does (p=(x,y))*.(*:r)=(+/(*:x,y))
prove if *./-.O=A,B  then A=:a0,a1 is parallel to B=:b0,b1 iff 0=(a0*b1)-a1*b0
prove if two lines are not parallel then they have exactly one point in common
prove if P=:p,q and (*:r)&gt;:+/*:P then P+A* intersects (*:r)=(+/(*:(0 1{))) twice
prove if A=:a0,a1 and B=:b0,b1 then (x,y)=(A +)(B *) iff x=a0 + b0 * and y=a1 + b1 *

Ordinary Equation For A Line
prove (x , y) = ((a0 , a1) +) ((b0 , b1) *) then
 x = a0 + b0 *
 y = a1 + b1 *
 ]
 (b % ~) (b *)
 ((b % ~) ]) (b *)
 ((b % ~) (a - ~ a +)) (b *)
 (b % ~) ((a - ~ a +) (b *))
 (b % ~) (a - ~ ((a +) (b *)))
 (b % ~) (a - ~) x
 NB. alternatively (and going along the classical route)
 (a0 , a1) + (b0 , b1) * t
 (a0 , a1) + (b0 * t) , (b1 * t)
 (x =: a0 + b0 * t) , (y =: a1 + b1 * t)
 t
 t * 1
 t * (b0 % b0)
 (t * b0) % b0
 (b0 * t) % b0
 (0 + b0 * t) % b0
 ((- a0) + a0 + b0 * t) % b0
 ((- a0) + x) % b0
 (x - a0) % b0
 t = (x - a0) % b0
 t = (y - a1) % b1  NB. By a similar argument.
prove the ordinary tacit form has x,y on the right
 (x , y) = (A +) (B *) 
 ]
 (B % ~) (B *)
 (B % ~ A - ~ A + B *)
 (B % ~ A - ~) (x , y)
 ] = (b0 % ~ a0 - ~) x
 ] = (b1 % ~ a1 - ~) y
 ((b0 % ~ a0 - ~) x) = ((b1 % ~ a1 - ~) y)
 y = (a1 + b1 * b0 % ~ a0 - ~) x

Trigonometry

Radian Measure
define x=mV p0 p1 p2 if *./(0&lt;:x),(x&lt;:o.1),(x%o.1)=(mclBV p1 1 p0 p2)%(mclB p1 1)
prove if x=mV p0 p1 p2 then (mclB p1 1)=o.1r2 implies x=mclBV p1 1 p0 p2
prove (deg x)=((o.1)%180)*(rad x)
note from now on: radians only
prove (x%o.1)=(mbdBV p0 1 p1 p2)%(mbdB p0 1)
if x&gt;:o.2 then "x rad" means "w rad" with *./(0&lt;:w),(w&lt;o.2),(x=w+n*o.2)
if *./(0&lt;z),(x=-z) then (rad x) means "w rad" with *./(0&lt;:w),(w&lt;o.2),(z=(n*o.2)-w)

Sine And Cosine
if *. / (O p2 K p3) , (-. p3 = O) , (p3 = (a , b)) then "sine V p3 O (1,0)" is b % r =: %: + / *: a , b
"cosine V p3 O (1,0)" is a%r
sine and cosine are independent of the point p3 (prove)
geometrically this means that any two such triangles are similar
if O 1 bdB p3=:a,b then (sine V p3 O (1,0))=b and (cosine V p3 O (1,0))=a
for O 1 bdB p3=:(a,b) define (sine mV p3 O (1,0))=b and (cosine mV p3 O (1,0))=a
the sign of sine and cosine depending on the quadrant its relevant angle occupies
Q1:+,+ Q2:-,+ Q3:-,- Q4:+,-
if (LA p0 p1 p2) then (sin V p1 p0 p2)=(d p1 p2)%(d p0 p1)
if (LA p0 p1 p2) then (cos V p1 p0 p2)=(d p0 p2)%(d p0 p1)
"sin x" is (sine rad x)
"cos x" is (cosine rad x)
from the definition of rad (for an arbitrary angle) (sin x)=sin x+n*o.2
(cos x) = cos x + n * o. 1
using plane geometry and the Pythagorean theorem:
=======================
x      sin x    cos x
-----------------------
o.1r6  1r2      (%:3)%2
o.1r41 %%:21    %%:2
o.1r3  (%:3)%2  1r2
o.1r2  1        0
o.1    0        _1
o.2    0        1
=======================
consider 1,1,%:2 and 1,(%:3),2 right triangles (and their angles)
reflect o.1r6, o.1r3, o.1 over longest leg and compute
if 1=$x then 1=+/*:(sin,cos)x since
 1
 (*: r) % *: r
 ((*: a) + *: b) % *: r
 ((*: a)% *: r) + (*: b) % *: r
 (*: a % r) + *: b % r
 + / *: ((a % r) , b % r)
 + / *: (sin x) , cos x
 + / *: (sin , cos) x
(cos x) = sin x + o. 1r2 and (sin x) = cos x - o. 1r2
(sin - x) = - sin x and (cos x) = cos - x
determine a distance using small angle measurements and a known length
polar coordinates
 r = %: + / *: x , y
 V =: mV (x , y) O (1 , 0)
 (x % r) = cos V
 (y % r) = sin V

The Graphs
plot ] , sin

The Tangent
tan =: sin % cos
tan only gives relevant information when -.0=cos
if *. / (O p2 K p3) , (-. p3 = O) , (p3 = a , b) then (b % a) = tan mV p3 O p2
tangent of the angle made by a line crossing the x-axis is the lines slope
 plot ],tan
we only plot tables of values
cot=: % tan 
sec=: % cos 
cosec =: % sin
1 = - / *: (tan , sec) x
1 = - / *: (csc , cot) x

Addition Formulas
(sin x + y) = ((sin x) * cos y) + (cos x) * sin y
(cos x + y) = ((cos x) * sin y) - (sin x) * sin y
(sin x - y) = ((sin x) * cos y) - (cos x) * sin y
(cos x - y) = ((cos x) * sin y) + (sin x) * sin y
(sin +: x) = +: * / (sin , cos) x
(cos +: x) = - / *: (cos , sin) x
(*: cos x) = (1 + cos +: x) % 2 or (+: *: cos x) = 1 + cos +: x
(*: sin x) = (1 - cos +: x) % 2 or (+: *: sin x) = 1 - cos +: x
(* / sin (m , n) * x) = -: - / cos (m (- , +) n) * x
(((sin m *) * (cos n *)) x) = -: + / sin (m (+ , -) n) * x
(* / cos (m , n) * x) = -: - / cos (m (+ , -) n) * x

Rotations
Since (r , V + x) = O x oV r , V then
 x0 = r * cos V
 y0 = r * sin V
 x1 = r * cos V + x
 x1 = r * ((cos V) * cos x) - (sin V) * sin x
 y1 = r * sin V + x
 y1 = r * ((sin V) * cos x) + (sin V) * cos x
 x1 = ((cos V) * x0) - (sin V) * y0
 y1 = ((sin V) * x0) + (cos V) * y0
the rotation matrix for x is 2 2 $ (cos , (- sin) , sin , cos) x
dilation matrix compositions of actions as multiplications of matrices

Some Analytic Geometry

The Straight Line Again
the plot of points for which c = F yields 1 is called the graph of F
an arbitrary point on the graph of ]=a* has the form (1 , a) *
a point on the graph of ] = (- ]) is of the form (1 , -1) *
the graph of [ = (b + a *) is a straight line parallel to the graph of [ = a * ]
 y1 =: y - b so y1 = a * x with points of the form (x , a * x) and [ = (b + a *) are (] , (b + a *))
the slope of a line that is the graph of [ = (b + a * ]) is a
*. / (y0 = b + a * x0) , y1 = b + a * x1 implies *. / ((y1 - y0) = a * x1 - x0) , a = (y1 - y0) % x1 - x0
(a = (y - y0) % x - x0) iff ((y - y0) % x - x0) = (y1 - y0) % x1 - x0
0 = c + (a * x) + b * y  equation of a line

The Parabola
(y - b) = c * (x - a) ^ 2 is called a parabola

The Ellipse
((a , b) *) shear dilation
1 = + / *: (u % a) , (v % b) is an ellipse

The Hyperbola
c = x * y is a hyperbola

Rotation Of Hyperbolas
c = - / *: y , xNotes on Constructive Mathematics by Errett Bishop, Douglas Bridges

A regular sequence is a Cauchy sequence whose modulus of convergence is the identity function.
Def. x is regular if (| (x n) - x m) &lt;: (% n) + % m
Def. x eq y if (| (x - y) n) &lt;: +: % n 
Lem. x eq y iff there exists N such that (N j) &lt;: n and (| (x - y) n) &lt;: % j
Prf. Let x eq y
(| (x - y) n) &lt;: +: % n 
(% -: n) = +: % n
N =: +:
(N j) &lt;: n
(N j) = +: j
(+: j) &lt;: n
j &lt;: -: n
(% -: n) &lt;: % j
(| (x - y) n) &lt;: % j
Therefore
N =: +:
(N j) &lt;: n
(| (x - y) n) &lt;: % j
Assume ((N j) &lt;: n) for some N
(| (x - y) n) &lt;: % j
Pick m so that (m &gt;: j &gt;. N j) then
j &lt;: m
% m &lt;: % j
(| (x - y) n) &lt;: A =: + / @ | ((x n) - x m) ,((x - y) m) , (y m) - y n
A &lt;: B =: + / ((% n) + % m) , (% j) , (% n) + % m
B &lt;: (+: % n) + 3 * % j
(| (x - y) n) &lt;: (+: % n) + 3 * % j  
(| (x - y) n) &lt;: +: % n   NB. needs proof
Therefore x eq y .
Prp. eq is an equivalence relation
Prf. Let x be regular.
(| (x n) - x m) &lt;: (% n) + % m
m =: n
(| (x n) - x n)) &lt;: (% n) + % n
((x - x) n) = (x n)- x n
(+: % n) = (% n) + % n
(| (x - x) n) &lt;: +: % n
Therefore x eq x .
Let x eq y
(| (x - y) n) &lt;: +: % n
(| (x - y)) = | (y - x)
(| (y - x) n) &lt;: +: % n
Therefore y eq x .
Let x eq y and y eq z
(| (x - y) n) &lt;: +: % n
(| (y - z) n) &lt;: +: % n
(| (x - z) n) &lt;: A =: (| (x - y) n) + | (y - z) n
A &lt;: B =: (+: % n) + +: % n
B = +: +: % n
(| (x - z) n) &lt;: +: +: % n
N =: +: +:
(N j) &lt;: n
(| (x - z) n) &lt;: % j
Therefore x eq z and eq is an equivalence relation.

Copyright John Meuser 2015
</pre></body></html>
